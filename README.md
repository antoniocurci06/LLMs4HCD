# LLMs for the Human-Centred Design
This repository stores the data for the experiment performed with Large Language Models to determine their impact on the design of evaluation protocols for usability studies.

The study was conducted in Italian, which is the reason why the available data is in the same language.

## Step 1: Prompt Creation
Starting from the objectives of the study, the prompt was refined iteratively by the researchers. 

## Step 2: Task Feasibility Analysis
The feasibility of the tasks was performed by three researchers who assigned a binary label (Yes/No) to each task, which indicates whether the task refers to a functionality that actually exists and is provided by the system. 

## Step 3: Interview with HCI Expert
The last step of the experiment consisted in carrying out a two-part interview with an HCI expert to gather insights regarding the tasks generated by the LLMs. 

This repository contains the complete version of the tables with the tasks generated for each platform. 
The folder ``Task Feasibility`` contains three Excel files:
- ``ChatGPT - Feasibility``: it stores every task generated with ChatGPT for each temperature and model.
- ``Mistral - Feasibility``: it stores every task generated with Mistral for each temperature and model.
- ``Gemini - Feasibility``: it stores every task generated with Gemini for each model.

For each task, two labels were assigned: one for the Feasibility and another that indicates whether the same task was generated in the human-led study.

For each group of tasks, the cosine-similarity with the human-generated ones was computed and reported in the last column.